def remove_after_eos(output_ids):
    cleaned_output = []
    for sequence in output_ids:
        eos_position = (sequence == 1).nonzero(as_tuple=True)[0]
        if len(eos_position) > 0:  # Nếu tìm thấy <EOS>
            cleaned_output.append(sequence[: eos_position[0]])  # Giữ lại từ đầu đến trước <EOS>
        else:
            cleaned_output.append(sequence)  # Không có <EOS>, giữ nguyên
    return cleaned_output

# Hàm huấn luyện
def train_model(model, tokenizer, train_data, validation_data, num_epochs, batch_size, lr, q_step):
    # no_improve_epochs = 0
    q = 0
    best_f1 = 0
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model.to(device)
    dataloader = build_dataloader(train_data=train_data, q = q, batch_size=batch_size, tokenizer=tokenizer)
    optimizer = AdamW(model.parameters(), lr=lr)
    for epoch in range(num_epochs):
        torch.cuda.empty_cache()
        # Huấn luyện #########################################################################################################################################
        print(f"Training epoch {epoch + 1}")
        model.train()
        total_loss = 0
        for batch in dataloader:
            outputs = model(
                input_ids=batch["input_ids"].to(device), 
                attention_mask=batch["attention_mask"].to(device), 
                labels=batch["labels"].to(device))
            loss = outputs.loss
            loss.backward()
            optimizer.step()
            optimizer.zero_grad()
            total_loss += loss.item()
            # Lưu dự đoán vào train_data
            if random.random() < q:
                for key, sequence in zip(batch["batch_keys"], torch.argmax(outputs.logits, dim=-1)):
                    eos_position = (sequence == 1).nonzero(as_tuple=True)[0]
                    if len(eos_position) > 0:  # Nếu tìm thấy <EOS>
                        train_data[key]["text_predict"] = tokenizer.decode(sequence[: eos_position[0]], skip_special_tokens=True)
                    else:
                        train_data[key]["text_predict"] = tokenizer.decode(sequence, skip_special_tokens=True) # Không có <EOS>, giữ nguyên
                    
        print(f"Epoch {epoch + 1} finished with loss: {total_loss / len(dataloader):.4f}")
        # Đánh giá #########################################################################################################################################
        print("Evaluating")
        model.eval()
        precision, recall, f1 = evaluate_pipeline_batch(model, tokenizer, validation_data, device, batch_size)
        print("precision =", precision,"recall =", recall,"f1 =", f1)
        if(f1 > best_f1):
            # no_improve_epochs = 0
            best_f1 = f1
            # Lưu model
            torch.save(model.state_dict(), f"/chain-of-thought-ABSA/results/experiment_4/{epoch + 1}.pt")
            print("New best_f1 =", best_f1)
        else:
            if (q >= 1):
                print("Huấn huyện xong")
                break
            q = q + q_step
            print("q =", q)
            dataloader = build_dataloader(train_data=train_data, q = q, batch_size=batch_size, tokenizer=tokenizer)
            # no_improve_epochs = no_improve_epochs + 1
            # if no_improve_epochs == 5:
            #     print("Huấn huyện xong")
            #     break

train_data = process_train_data("/chain-of-thought-ABSA/data/acos/laptop16/train.txt")

train_model(
    model = T5ForConditionalGeneration.from_pretrained("t5-base"), 
    tokenizer = T5Tokenizer.from_pretrained("t5-base"), 
    train_data = train_data,
    validation_data = process_validation_data("/chain-of-thought-ABSA/data/acos/laptop16/dev.txt"),
    num_epochs = 1000,
    batch_size = 8, 
    lr = 3e-5,
    q_step=0.05,
)

Epoch 1 finished with loss: 0.5845
Evaluating
precision = 0.29411764705882354 recall = 0.2733485193621868 f1 = 0.28335301062573787
New best_f1 = 0.28335301062573787
Training epoch 2
Epoch 2 finished with loss: 0.2440
Evaluating
precision = 0.3980815347721823 recall = 0.37813211845102507 f1 = 0.3878504672897196
New best_f1 = 0.3878504672897196
Training epoch 3
Epoch 3 finished with loss: 0.1806
Evaluating
precision = 0.4092009685230024 recall = 0.38496583143507973 f1 = 0.3967136150234742
New best_f1 = 0.3967136150234742
Training epoch 4
Epoch 4 finished with loss: 0.1424
Evaluating
precision = 0.3981042654028436 recall = 0.3826879271070615 f1 = 0.3902439024390244
q = 0.05
Training epoch 5
Epoch 5 finished with loss: 0.1154
Evaluating
precision = 0.4421768707482993 recall = 0.44419134396355353 f1 = 0.4431818181818182
New best_f1 = 0.4431818181818182
Training epoch 6
Epoch 6 finished with loss: 0.0961
Evaluating
precision = 0.4288990825688073 recall = 0.42596810933940776 f1 = 0.42742857142857144
q = 0.1
Training epoch 7
Epoch 7 finished with loss: 0.0808
Evaluating
precision = 0.46744186046511627 recall = 0.45785876993166286 f1 = 0.4626006904487917
New best_f1 = 0.4626006904487917
Training epoch 8
Epoch 8 finished with loss: 0.0709
Evaluating
precision = 0.42921348314606744 recall = 0.43507972665148065 f1 = 0.4321266968325792
q = 0.15000000000000002
Training epoch 9
Epoch 9 finished with loss: 0.0629
Evaluating
precision = 0.4823529411764706 recall = 0.46697038724373574 f1 = 0.4745370370370371
New best_f1 = 0.4745370370370371
Training epoch 10
Epoch 10 finished with loss: 0.0539
Evaluating
precision = 0.45774647887323944 recall = 0.44419134396355353 f1 = 0.45086705202312144
q = 0.2
Training epoch 11
Epoch 11 finished with loss: 0.0492
Evaluating
precision = 0.45977011494252873 recall = 0.45558086560364464 f1 = 0.45766590389016015
q = 0.25
Training epoch 12
Epoch 12 finished with loss: 0.0410
Evaluating
precision = 0.46485260770975056 recall = 0.46697038724373574 f1 = 0.4659090909090909
q = 0.3
Training epoch 13
Epoch 13 finished with loss: 0.0376
Evaluating
precision = 0.46485260770975056 recall = 0.46697038724373574 f1 = 0.4659090909090909
q = 0.35
Training epoch 14
Epoch 14 finished with loss: 0.0332
Evaluating
precision = 0.4641255605381166 recall = 0.4715261958997722 f1 = 0.46779661016949153
q = 0.39999999999999997
Training epoch 15
Epoch 15 finished with loss: 0.0309
Evaluating
precision = 0.49195402298850577 recall = 0.4874715261958998 f1 = 0.48970251716247143
New best_f1 = 0.48970251716247143
Training epoch 16
Epoch 16 finished with loss: 0.0271
Evaluating
precision = 0.46543778801843316 recall = 0.4601366742596811 f1 = 0.4627720504009164
q = 0.44999999999999996
Training epoch 17
Epoch 17 finished with loss: 0.0238
Evaluating
precision = 0.46308724832214765 recall = 0.4715261958997722 f1 = 0.4672686230248307
q = 0.49999999999999994
Training epoch 18
Epoch 18 finished with loss: 0.0209
Evaluating
precision = 0.46799116997792495 recall = 0.48291571753986334 f1 = 0.47533632286995514
q = 0.5499999999999999
Training epoch 19
Epoch 19 finished with loss: 0.0187
Evaluating
precision = 0.44666666666666666 recall = 0.45785876993166286 f1 = 0.45219347581552305
q = 0.6
Training epoch 20
Epoch 20 finished with loss: 0.0173
Evaluating
precision = 0.44819819819819817 recall = 0.4533029612756264 f1 = 0.4507361268403171
q = 0.65
Training epoch 21
Epoch 21 finished with loss: 0.0163
Evaluating
precision = 0.45496535796766746 recall = 0.44874715261959 f1 = 0.4518348623853211
q = 0.7000000000000001
Training epoch 22
Epoch 22 finished with loss: 0.0143
Evaluating
precision = 0.44954128440366975 recall = 0.44646924829157175 f1 = 0.448
q = 0.7500000000000001
Training epoch 23
Epoch 23 finished with loss: 0.0134
Evaluating
precision = 0.47019867549668876 recall = 0.48519362186788156 f1 = 0.47757847533632286
q = 0.8000000000000002
Training epoch 24
Epoch 24 finished with loss: 0.0137
Evaluating
precision = 0.4442013129102845 recall = 0.4624145785876993 f1 = 0.453125
q = 0.8500000000000002
Training epoch 25
Epoch 25 finished with loss: 0.0114
Evaluating
precision = 0.4646924829157175 recall = 0.4646924829157175 f1 = 0.46469248291571746
q = 0.9000000000000002
Training epoch 26
Epoch 26 finished with loss: 0.0114
Evaluating
precision = 0.46744186046511627 recall = 0.45785876993166286 f1 = 0.4626006904487917
q = 0.9500000000000003
Training epoch 27
Epoch 27 finished with loss: 0.0107
Evaluating
precision = 0.45852534562211983 recall = 0.4533029612756264 f1 = 0.4558991981672394
q = 1.0000000000000002
Training epoch 28
Epoch 28 finished with loss: 0.0090
Evaluating
precision = 0.4728132387706856 recall = 0.45558086560364464 f1 = 0.4640371229698376
Huấn huyện xong

đánh giá trên tập test:
(0.4256816182937555, 0.4186851211072664, 0.4221543829044919)