{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# xây dựng tập huấn luyện"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import random\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_train_data(file_path):\n",
    "    # Đọc dữ liệu từ file\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        lines = f.readlines()\n",
    "    # Tạo các tác vụ\n",
    "    task_data = {}\n",
    "    for i in range(len(lines)):\n",
    "        text_sentence, aspect_category_sentiment_opinions_str = lines[i].strip().split(\"####\")\n",
    "        aspect_category_sentiment_opinions = ast.literal_eval(aspect_category_sentiment_opinions_str)\n",
    "        # Tạo các chuỗi cần thiết\n",
    "        aspects_str = \"; \".join(sorted(set([aspect for aspect, _, _, _ in aspect_category_sentiment_opinions])))\n",
    "        opinions_str = \"; \".join(sorted(set([opinion for _, _, _, opinion in aspect_category_sentiment_opinions])))\n",
    "        aspect_opinions_str = \"; \".join(sorted(set([f\"{aspect}, {opinion}\" for aspect, _, _, opinion in aspect_category_sentiment_opinions])))\n",
    "        aspect_category_sentiment_opinions_str = \"; \".join(sorted([f\"{aspect}, {category}, {sentiment}, {opinion}\" for aspect, category, sentiment, opinion in aspect_category_sentiment_opinions]))\n",
    "\n",
    "        # Tác vụ 1: I -> A\n",
    "        task_data[f\"{i}_1\"] = {\n",
    "            \"id\": i,\n",
    "            \"task\": 1,\n",
    "            \"text_input\": f\"Task 1, predict aspect terms\\nInput: {text_sentence}\",\n",
    "            \"text_label\": aspects_str,\n",
    "            \"text_predict\": aspects_str,\n",
    "            \"text_sentence\": text_sentence,\n",
    "        }\n",
    "        # Tác vụ 2: I -> O\n",
    "        task_data[f\"{i}_2\"] = {\n",
    "            \"id\": i,\n",
    "            \"task\": 2,\n",
    "            \"text_input\": f\"Task 2, predict opinion terms\\nInput: {text_sentence}\",\n",
    "            \"text_label\": opinions_str,\n",
    "            \"text_predict\": opinions_str,\n",
    "            \"text_sentence\": text_sentence,\n",
    "        }\n",
    "        # Tác vụ 3: I, A -> A-O\n",
    "        task_data[f\"{i}_3\"] = {\n",
    "            \"id\": i,\n",
    "            \"task\": 3,\n",
    "            \"text_input\": f\"Task 3, predict aspect term - opinion term sets with these aspect terms\\nInput: {text_sentence}\\nAspect terms: {aspects_str}\",\n",
    "            \"text_label\": aspect_opinions_str,\n",
    "            \"text_predict\": aspect_opinions_str,\n",
    "            \"text_sentence\": text_sentence,\n",
    "        }\n",
    "        # Tác vụ 4: I, O -> A-O\n",
    "        task_data[f\"{i}_4\"] = {\n",
    "            \"id\": i,\n",
    "            \"task\": 4,\n",
    "            \"text_input\": f\"Task 4, predict aspect term - opinion term sets with these opinion terms\\nInput: {text_sentence}\\nOpinion terms: {opinions_str}\",\n",
    "            \"text_label\": aspect_opinions_str,\n",
    "            \"text_predict\": aspect_opinions_str,\n",
    "            \"text_sentence\": text_sentence,\n",
    "        }\n",
    "        # Tác vụ 5: I, A, O -> A-O\n",
    "        task_data[f\"{i}_5\"] = {\n",
    "            \"id\": i,\n",
    "            \"task\": 5,\n",
    "            \"text_input\": f\"Task 5, predict aspect term - opinion term sets with these aspect terms and opinion terms\\nInput: {text_sentence}\\nAspect terms: {aspects_str}\\nOpinion terms: {opinions_str}\",\n",
    "            \"text_label\": aspect_opinions_str,\n",
    "            \"text_predict\": aspect_opinions_str,\n",
    "            \"text_sentence\": text_sentence,\n",
    "        }\n",
    "        # Tác vụ 6: I, A-O, A-O, A-O -> A-O\n",
    "        task_data[f\"{i}_6\"] = {\n",
    "            \"id\": i,\n",
    "            \"task\": 6,\n",
    "            \"text_input\": f\"Task 6, predict aspect term - opinion term sets with results of task 3, 4, 5\\nInput: {text_sentence}\\nTask 3 results: {aspect_opinions_str}\\nTask 4 results: {aspect_opinions_str}\\nTask 5 results: {aspect_opinions_str}\",\n",
    "            \"text_label\": aspect_opinions_str,\n",
    "            \"text_predict\": aspect_opinions_str,\n",
    "            \"text_sentence\": text_sentence,\n",
    "        }\n",
    "        # Tác vụ 7: I, A-O -> A-C-S-O\n",
    "        task_data[f\"{i}_7\"] = {\n",
    "            \"id\": i,\n",
    "            \"task\": 7,\n",
    "            \"text_input\": f\"Task 7, predict aspect term - aspect category - sentiment polarity - opinion term sets with these aspect term - opinion term sets\\nInput: {text_sentence}\\nAspect term - opinion term sets: {aspect_opinions_str}\",\n",
    "            \"text_label\": aspect_category_sentiment_opinions_str,\n",
    "            \"text_predict\": aspect_category_sentiment_opinions_str,\n",
    "            \"text_sentence\": text_sentence,\n",
    "        }\n",
    "    return task_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Đường dẫn đến file\n",
    "# train_data = process_train_data(\"/chain-of-thought-ABSA/data/acos/rest16/train.txt\")\n",
    "# train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch_keys, train_data, q, tokenizer):\n",
    "    text_inputs, text_labels = [], []\n",
    "    for key in batch_keys:\n",
    "        item_data = train_data[key]\n",
    "\n",
    "        id = item_data[\"id\"]\n",
    "        task = item_data['task']\n",
    "        text_input = item_data[\"text_input\"]\n",
    "        text_label = item_data[\"text_label\"]\n",
    "        # text_predict = item_data[\"text_predict\"]\n",
    "        text_sentence = item_data[\"text_sentence\"]\n",
    "\n",
    "        # Task 3: Sử dụng predict từ task1\n",
    "        if task == 3 and random.random() < q:\n",
    "            aspects = train_data[f\"{id}_1\"][\"text_predict\"]\n",
    "            text_input = f\"Task 3, predict aspect term - opinion term sets with these aspect terms\\nInput: {text_sentence}\\nAspect terms: {aspects}\"\n",
    "        # Task 4: Sử dụng predict từ task2\n",
    "        if task == 4 and random.random() < q:\n",
    "            opinions = train_data[f\"{id}_2\"][\"text_predict\"]\n",
    "            text_input = f\"Task 4, predict aspect term - opinion term sets with these opinion terms\\nInput: {text_sentence}\\nOpinion terms: {opinions}\"\n",
    "        # Task 5: Sử dụng predict từ task1 và task2\n",
    "        if task == 5:\n",
    "            aspects = train_data[f\"{id}_1\"][\"text_predict\"] if random.random() < q else train_data[f\"{id}_1\"][\"text_label\"]\n",
    "            opinions = train_data[f\"{id}_2\"][\"text_predict\"] if random.random() < q else train_data[f\"{id}_2\"][\"text_label\"]\n",
    "            text_input = f\"Task 5, predict aspect term - opinion term sets with these aspect terms and opinion terms\\nInput: {text_sentence}\\nAspect terms: {aspects}\\nOpinion terms: {opinions}\"\n",
    "        # Task 6: Sử dụng predict từ task3, task4, task5\n",
    "        if task == 6:\n",
    "            result_3 = train_data[f\"{id}_3\"][\"text_predict\"] if random.random() < q else train_data[f\"{id}_3\"][\"text_label\"]\n",
    "            result_4 = train_data[f\"{id}_4\"][\"text_predict\"] if random.random() < q else train_data[f\"{id}_4\"][\"text_label\"]\n",
    "            result_5 = train_data[f\"{id}_5\"][\"text_predict\"] if random.random() < q else train_data[f\"{id}_5\"][\"text_label\"]\n",
    "            text_input = f\"Task 6, predict aspect term - opinion term sets with results of task 3, 4, 5\\nInput: {text_sentence}\\nTask 3 results: {result_3}\\nTask 4 results: {result_4}\\nTask 5 results: {result_5}\"\n",
    "        # Task 7: Sử dụng predict từ task6\n",
    "        if task == 7 and random.random() < q:\n",
    "            aspect_opinions = train_data[f\"{id}_6\"][\"text_predict\"]\n",
    "            text_input = f\"Task 7, predict aspect term - aspect category - sentiment polarity - opinion term sets with these aspect term - opinion term sets\\nInput: {text_sentence}\\nAspect term - opinion term sets: {aspect_opinions}\"\n",
    "        \n",
    "        # Tokenize inputs and labels\n",
    "        text_inputs.append(text_input)\n",
    "        text_labels.append(text_label)\n",
    "    \n",
    "    # Tokenize the entire batch\n",
    "    tokenized_inputs = tokenizer(text_inputs, padding=True, return_tensors=\"pt\")\n",
    "    tokenized_labels = tokenizer(text_labels, padding=True, return_tensors=\"pt\")\n",
    "    tokenized_labels[\"input_ids\"][tokenized_labels[\"input_ids\"] == tokenizer.pad_token_id] = -100\n",
    "    # Return the batch as a dictionary\n",
    "    return {\n",
    "        \"batch_keys\": batch_keys,\n",
    "        \"input_ids\": tokenized_inputs[\"input_ids\"],\n",
    "        \"attention_mask\": tokenized_inputs[\"attention_mask\"],\n",
    "        \"labels\": tokenized_labels[\"input_ids\"],\n",
    "        # \"text_inputs\": text_inputs,\n",
    "        # \"text_labels\": text_labels,\n",
    "    }\n",
    "\n",
    "def build_dataloader(train_data, q, batch_size, tokenizer):\n",
    "    return DataLoader(\n",
    "        list(train_data.keys()),\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,  # Shuffle để tăng tính ngẫu nhiên\n",
    "        collate_fn=lambda batch_keys: collate_fn(batch_keys=batch_keys, train_data=train_data, q=q, tokenizer=tokenizer)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader = build_dataloader(train_data, 0.5, 1, T5Tokenizer.from_pretrained(\"t5-base\"))\n",
    "# max_len_input_ids = 0\n",
    "# max_len_labels = 0\n",
    "# for batch in dataloader:\n",
    "#     if max_len_input_ids < len(batch['input_ids'][0]):\n",
    "#         max_len_input_ids = len(batch['input_ids'][0])\n",
    "    \n",
    "#     if max_len_labels < len(batch['labels'][0]):\n",
    "#         max_len_labels = len(batch['labels'][0])\n",
    "# print(max_len_input_ids, max_len_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# xử lý tập validation và đánh giá mô hình"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === HÀM XỬ LÝ VALIDATION DATA ===\n",
    "def process_validation_data(validation_file):\n",
    "    # Đọc dữ liệu từ file\n",
    "    with open(validation_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        lines = f.readlines()\n",
    "    data = []\n",
    "    for line in lines:\n",
    "        text_sentence, aspect_category_sentiment_opinions_str = line.strip().split(\"####\")\n",
    "        data.append({\n",
    "            \"text_sentence\": text_sentence, \n",
    "            \"aspect_category_sentiment_opinions\": ast.literal_eval(aspect_category_sentiment_opinions_str)\n",
    "        })\n",
    "    return data\n",
    "\n",
    "# === HÀM ĐỂ CHẠY SUY LUẬN TRÊN BATCH ===\n",
    "def batch_predict(model, tokenizer, inputs, device):\n",
    "    encoded_inputs = tokenizer(inputs, return_tensors=\"pt\", padding=True).to(device)\n",
    "    outputs = model.generate(**encoded_inputs, max_length=124)\n",
    "    return tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "\n",
    "def evaluate_pipeline_batch(model, tokenizer, validation_data, device, batch_size):\n",
    "    # Initialize counters\n",
    "    count_true_positive = 0\n",
    "    count_false_positive = 0\n",
    "    count_false_negative = 0\n",
    "    \n",
    "    # Divide validation data into batches\n",
    "    for i in range(0, len(validation_data), batch_size):\n",
    "        batch = validation_data[i:i + batch_size]\n",
    "        text_sentences = [sample[\"text_sentence\"] for sample in batch]\n",
    "        text_labels = [sample[\"aspect_category_sentiment_opinions\"] for sample in batch]\n",
    "\n",
    "        # Step 1: Task 1 (I -> A)\n",
    "        task_1_inputs = [\n",
    "            f\"Task 1, predict aspect terms\\nInput: {text_sentence}\"\n",
    "            for text_sentence in text_sentences]\n",
    "        task_1_outputs = batch_predict(model, tokenizer, task_1_inputs, device)\n",
    "        # print(\"task_1_inputs = \", task_1_inputs)\n",
    "        # print(\"task_1_outputs = \", task_1_outputs)\n",
    "        # Step 2: Task 2 (I -> O)\n",
    "        task_2_inputs = [\n",
    "            f\"Task 2, predict opinion terms\\nInput: {text_sentence}\" \n",
    "            for text_sentence in text_sentences]\n",
    "        task_2_outputs = batch_predict(model, tokenizer, task_2_inputs, device)\n",
    "        # print(\"task_2_inputs = \", task_2_inputs)\n",
    "        # print(\"task_2_outputs = \", task_2_outputs)\n",
    "        # Step 3: Task 3 (I, A -> A-O)\n",
    "        task_3_inputs = [\n",
    "            f\"Task 3, predict aspect term - opinion term sets with these aspect terms\\nInput: {text_sentence}\\nAspect terms: {task_1_output}\"\n",
    "            for text_sentence, task_1_output in zip(text_sentences, task_1_outputs)\n",
    "        ]\n",
    "        task_3_outputs = batch_predict(model, tokenizer, task_3_inputs, device)\n",
    "        # print(\"task_3_inputs = \", task_3_inputs)\n",
    "        # print(\"task_3_outputs = \", task_3_outputs)\n",
    "        # Step 4: Task 4 (I, O -> A-O)\n",
    "        task_4_inputs = [\n",
    "            f\"Task 4, predict aspect term - opinion term sets with these opinion terms\\nInput: {text_sentence}\\nOpinion terms: {task_2_output}\"\n",
    "            for text_sentence, task_2_output in zip(text_sentences, task_2_outputs)\n",
    "        ]\n",
    "        task_4_outputs = batch_predict(model, tokenizer, task_4_inputs, device)\n",
    "        # print(\"task_4_inputs = \", task_4_inputs)\n",
    "        # print(\"task_4_outputs = \", task_4_outputs)\n",
    "        # Step 5: Task 5 (I, A, O -> A-O)\n",
    "        task_5_inputs = [\n",
    "            f\"Task 5, predict aspect term - opinion term sets with these aspect terms and opinion terms\\nInput: {text_sentence}\\nAspect terms: {task_1_output}\\nOpinion terms: {task_2_output}\"\n",
    "            for text_sentence, task_1_output, task_2_output in zip(text_sentences, task_1_outputs, task_2_outputs)\n",
    "        ]\n",
    "        task_5_outputs = batch_predict(model, tokenizer, task_5_inputs, device)\n",
    "        # print(\"task_5_inputs = \", task_5_inputs)\n",
    "        # print(\"task_5_outputs = \", task_5_outputs)\n",
    "        # Step 6: Task 6 (I, A-O -> A-O)\n",
    "        task_6_inputs = [\n",
    "            f\"Task 6, predict aspect term - opinion term sets with results of task 3, 4, 5\\nInput: {text_sentence}\\nTask 3 results: {task_3_output}\\nTask 4 results: {task_4_output}\\nTask 5 results: {task_5_output}\"\n",
    "            for text_sentence, task_3_output, task_4_output, task_5_output in zip(text_sentences, task_3_outputs, task_4_outputs, task_5_outputs)\n",
    "        ]\n",
    "        task_6_outputs = batch_predict(model, tokenizer, task_6_inputs, device)\n",
    "        # print(\"task_6_inputs = \", task_6_inputs)\n",
    "        # print(\"task_6_outputs = \", task_6_outputs)\n",
    "        # Step 7: Task 7 (I, A-O -> A-O-S)\n",
    "        task_7_inputs = [\n",
    "            f\"Task 7, predict aspect term - aspect category - sentiment polarity - opinion term sets with these aspect term - opinion term sets\\nInput: {text_sentence}\\nAspect term - opinion term sets: {task_6_output}\"\n",
    "            for text_sentence, task_6_output in zip(text_sentences, task_6_outputs)\n",
    "        ]\n",
    "        task_7_outputs = batch_predict(model, tokenizer, task_7_inputs, device)\n",
    "        # print(\"task_7_inputs = \", task_7_inputs)\n",
    "        # print(\"task_7_outputs = \", task_7_outputs)\n",
    "        # print(\"text_labels = \", text_labels)\n",
    "        # return 0, 0, 0\n",
    "        # Evaluate predictions\n",
    "        for task_7_output, text_label in zip(task_7_outputs, text_labels):\n",
    "            predicted_set = set(task_7_output.split('; '))  # Split predictions into sets of tuples\n",
    "            true_set = set(f\"{aspect}, {category}, {sentiment}, {opinion}\" for aspect, category, sentiment, opinion in text_label) # Split ground truth into sets of tuples\n",
    "            # Calculate true positives, false positives, and false negatives\n",
    "            count_true_positive += len(predicted_set & true_set)\n",
    "            count_false_positive += len(predicted_set - true_set)\n",
    "            count_false_negative += len(true_set - predicted_set)\n",
    "    \n",
    "    # Compute Precision, Recall, and F1-score\n",
    "    precision = count_true_positive / (count_true_positive + count_false_positive) if count_true_positive + count_false_positive > 0 else 0\n",
    "    recall = count_true_positive / (count_true_positive + count_false_negative) if count_true_positive + count_false_negative > 0 else 0\n",
    "    f1 = (2 * precision * recall) / (precision + recall) if precision + recall > 0 else 0\n",
    "    \n",
    "    return precision, recall, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Đánh giá trên tập test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data = process_validation_data(\"/chain-of-thought-ABSA/data/acos/laptop16/test.txt\")\n",
    "\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"t5-base\")\n",
    "model.load_state_dict(torch.load(\"/chain-of-thought-ABSA/results/experiment_4/17.pt\"))\n",
    "model.eval()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "evaluate_pipeline_batch(\n",
    "    model=model, \n",
    "    tokenizer = T5Tokenizer.from_pretrained(\"t5-base\"), \n",
    "    validation_data = validation_data, \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"), \n",
    "    batch_size = 16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Huấn luyện"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_after_eos(output_ids):\n",
    "    cleaned_output = []\n",
    "    for sequence in output_ids:\n",
    "        eos_position = (sequence == 1).nonzero(as_tuple=True)[0]\n",
    "        if len(eos_position) > 0:  # Nếu tìm thấy <EOS>\n",
    "            cleaned_output.append(sequence[: eos_position[0]])  # Giữ lại từ đầu đến trước <EOS>\n",
    "        else:\n",
    "            cleaned_output.append(sequence)  # Không có <EOS>, giữ nguyên\n",
    "    return cleaned_output\n",
    "\n",
    "# Hàm huấn luyện\n",
    "def train_model(model, tokenizer, train_data, validation_data, num_epochs, batch_size, lr, q_step):\n",
    "    # no_improve_epochs = 0\n",
    "    q = 0\n",
    "    best_f1 = 0\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    dataloader = build_dataloader(train_data=train_data, q = q, batch_size=batch_size, tokenizer=tokenizer)\n",
    "    optimizer = AdamW(model.parameters(), lr=lr)\n",
    "    for epoch in range(num_epochs):\n",
    "        torch.cuda.empty_cache()\n",
    "        # Huấn luyện #########################################################################################################################################\n",
    "        print(f\"Training epoch {epoch + 1}\")\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for batch in dataloader:\n",
    "            outputs = model(\n",
    "                input_ids=batch[\"input_ids\"].to(device), \n",
    "                attention_mask=batch[\"attention_mask\"].to(device), \n",
    "                labels=batch[\"labels\"].to(device))\n",
    "            loss = outputs.loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            total_loss += loss.item()\n",
    "            # Lưu dự đoán vào train_data\n",
    "            if random.random() < q:\n",
    "                output_ids = torch.argmax(outputs.logits, dim=-1)\n",
    "                output_ids = remove_after_eos(output_ids)\n",
    "                for key, prediction in zip(batch[\"batch_keys\"], tokenizer.batch_decode(output_ids, skip_special_tokens=True)):\n",
    "                    train_data[key][\"text_predict\"] = prediction\n",
    "                    \n",
    "        print(f\"Epoch {epoch + 1} finished with loss: {total_loss / len(dataloader):.4f}\")\n",
    "        # Đánh giá #########################################################################################################################################\n",
    "        print(\"Evaluating\")\n",
    "        model.eval()\n",
    "        precision, recall, f1 = evaluate_pipeline_batch(model, tokenizer, validation_data, device, batch_size)\n",
    "        print(\"precision =\", precision,\"recall =\", recall,\"f1 =\", f1)\n",
    "        if(f1 > best_f1):\n",
    "            # no_improve_epochs = 0\n",
    "            best_f1 = f1\n",
    "            # Lưu model\n",
    "            torch.save(model.state_dict(), f\"/chain-of-thought-ABSA/results/experiment_4/{epoch + 1}.pt\")\n",
    "            print(\"New best_f1 =\", best_f1)\n",
    "        else:\n",
    "            if (q >= 1):\n",
    "                print(\"Huấn huyện xong\")\n",
    "                break\n",
    "            q = q + q_step\n",
    "            print(\"q =\", q)\n",
    "            dataloader = build_dataloader(train_data=train_data, q = q, batch_size=batch_size, tokenizer=tokenizer)\n",
    "            # no_improve_epochs = no_improve_epochs + 1\n",
    "            # if no_improve_epochs == 5:\n",
    "            #     print(\"Huấn huyện xong\")\n",
    "            #     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = process_train_data(\"/chain-of-thought-ABSA/data/acos/laptop16/train.txt\")\n",
    "\n",
    "train_model(\n",
    "    model = T5ForConditionalGeneration.from_pretrained(\"t5-base\"), \n",
    "    tokenizer = T5Tokenizer.from_pretrained(\"t5-base\"), \n",
    "    train_data = train_data,\n",
    "    validation_data = process_validation_data(\"/chain-of-thought-ABSA/data/acos/laptop16/dev.txt\"),\n",
    "    num_epochs = 1000,\n",
    "    batch_size = 16, \n",
    "    lr = 3e-5,\n",
    "    q_step=0.05,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
