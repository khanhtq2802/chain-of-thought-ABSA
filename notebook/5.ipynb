{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# xây dựng tập huấn luyện"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import random\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_train_data(file_path):\n",
    "    # Đọc dữ liệu từ file\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        lines = f.readlines()\n",
    "    # Tạo các tác vụ\n",
    "    task_data = {}\n",
    "    for i in range(len(lines)):\n",
    "        text_sentence, aspect_category_sentiment_opinions_str = lines[i].strip().split(\"####\")\n",
    "        aspect_category_sentiment_opinions = ast.literal_eval(aspect_category_sentiment_opinions_str)\n",
    "        # Tạo các chuỗi cần thiết\n",
    "        aspects_str = \"; \".join(sorted(set([aspect for aspect, _, _, _ in aspect_category_sentiment_opinions])))\n",
    "        opinions_str = \"; \".join(sorted(set([opinion for _, _, _, opinion in aspect_category_sentiment_opinions])))\n",
    "        aspect_opinions_str = \"; \".join(sorted(set([f\"{aspect}, {opinion}\" for aspect, _, _, opinion in aspect_category_sentiment_opinions])))\n",
    "        aspect_opinion_sentiment_categories_str = \"; \".join(sorted([f\"{aspect}, {opinion}, {sentiment}, {category}\" for aspect, category, sentiment, opinion in aspect_category_sentiment_opinions]))\n",
    "\n",
    "        # Tác vụ 1: I -> A\n",
    "        task_data[f\"{i}_1\"] = {\n",
    "            \"id\": i,\n",
    "            \"task\": 1,\n",
    "            \"text_input\": f\"Task 1, predict aspect terms\\nInput: {text_sentence}\",\n",
    "            \"text_label\": aspects_str,\n",
    "            \"text_predict\": aspects_str,\n",
    "            \"text_sentence\": text_sentence,\n",
    "        }\n",
    "        # Tác vụ 2: I -> O\n",
    "        task_data[f\"{i}_2\"] = {\n",
    "            \"id\": i,\n",
    "            \"task\": 2,\n",
    "            \"text_input\": f\"Task 2, predict opinion terms\\nInput: {text_sentence}\",\n",
    "            \"text_label\": opinions_str,\n",
    "            \"text_predict\": opinions_str,\n",
    "            \"text_sentence\": text_sentence,\n",
    "        }\n",
    "        # Tác vụ 3: I, A -> A-O\n",
    "        task_data[f\"{i}_3\"] = {\n",
    "            \"id\": i,\n",
    "            \"task\": 3,\n",
    "            \"text_input\": f\"Task 3, predict aspect term - opinion term sets with these aspect terms\\nInput: {text_sentence}\\nAspect terms: {aspects_str}\",\n",
    "            \"text_label\": aspect_opinions_str,\n",
    "            \"text_predict\": aspect_opinions_str,\n",
    "            \"text_sentence\": text_sentence,\n",
    "        }\n",
    "        # Tác vụ 4: I, O -> A-O\n",
    "        task_data[f\"{i}_4\"] = {\n",
    "            \"id\": i,\n",
    "            \"task\": 4,\n",
    "            \"text_input\": f\"Task 4, predict aspect term - opinion term sets with these opinion terms\\nInput: {text_sentence}\\nOpinion terms: {opinions_str}\",\n",
    "            \"text_label\": aspect_opinions_str,\n",
    "            \"text_predict\": aspect_opinions_str,\n",
    "            \"text_sentence\": text_sentence,\n",
    "        }\n",
    "        # Tác vụ 5: I, A, O -> A-O\n",
    "        task_data[f\"{i}_5\"] = {\n",
    "            \"id\": i,\n",
    "            \"task\": 5,\n",
    "            \"text_input\": f\"Task 5, predict aspect term - opinion term sets with these aspect terms and opinion terms\\nInput: {text_sentence}\\nAspect terms: {aspects_str}\\nOpinion terms: {opinions_str}\",\n",
    "            \"text_label\": aspect_opinions_str,\n",
    "            \"text_predict\": aspect_opinions_str,\n",
    "            \"text_sentence\": text_sentence,\n",
    "        }\n",
    "        # Tác vụ 6: I, A-O, A-O, A-O -> A-O-S-C\n",
    "        task_data[f\"{i}_6\"] = {\n",
    "            \"id\": i,\n",
    "            \"task\": 6,\n",
    "            \"text_input\": f\"Task 6, predict aspect term - opinion term - sentiment polarity - aspect category sets with results of task 3, 4, 5\\nInput: {text_sentence}\\nTask 3 results: {aspect_opinions_str}\\nTask 4 results: {aspect_opinions_str}\\nTask 5 results: {aspect_opinions_str}\",\n",
    "            \"text_label\": aspect_opinion_sentiment_categories_str,\n",
    "            \"text_predict\": aspect_opinion_sentiment_categories_str,\n",
    "            \"text_sentence\": text_sentence,\n",
    "        }\n",
    "    return task_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Đường dẫn đến file\n",
    "# train_data = process_train_data(\"/chain-of-thought-ABSA/data/acos/rest16/train.txt\")\n",
    "# train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch_keys, train_data, q, tokenizer):\n",
    "    text_inputs, text_labels = [], []\n",
    "    for key in batch_keys:\n",
    "        item_data = train_data[key]\n",
    "\n",
    "        id = item_data[\"id\"]\n",
    "        task = item_data['task']\n",
    "        text_input = item_data[\"text_input\"]\n",
    "        text_label = item_data[\"text_label\"]\n",
    "        # text_predict = item_data[\"text_predict\"]\n",
    "        text_sentence = item_data[\"text_sentence\"]\n",
    "\n",
    "        # Task 3: Sử dụng predict từ task1\n",
    "        if task == 3 and random.random() < q:\n",
    "            aspects = train_data[f\"{id}_1\"][\"text_predict\"]\n",
    "            text_input = f\"Task 3, predict aspect term - opinion term sets with these aspect terms\\nInput: {text_sentence}\\nAspect terms: {aspects}\"\n",
    "        # Task 4: Sử dụng predict từ task2\n",
    "        if task == 4 and random.random() < q:\n",
    "            opinions = train_data[f\"{id}_2\"][\"text_predict\"]\n",
    "            text_input = f\"Task 4, predict aspect term - opinion term sets with these opinion terms\\nInput: {text_sentence}\\nOpinion terms: {opinions}\"\n",
    "        # Task 5: Sử dụng predict từ task1 và task2\n",
    "        if task == 5:\n",
    "            aspects = train_data[f\"{id}_1\"][\"text_predict\"] if random.random() < q else train_data[f\"{id}_1\"][\"text_label\"]\n",
    "            opinions = train_data[f\"{id}_2\"][\"text_predict\"] if random.random() < q else train_data[f\"{id}_2\"][\"text_label\"]\n",
    "            text_input = f\"Task 5, predict aspect term - opinion term sets with these aspect terms and opinion terms\\nInput: {text_sentence}\\nAspect terms: {aspects}\\nOpinion terms: {opinions}\"\n",
    "        # Task 6: Sử dụng predict từ task3, task4, task5\n",
    "        if task == 6:\n",
    "            result_3 = train_data[f\"{id}_3\"][\"text_predict\"] if random.random() < q else train_data[f\"{id}_3\"][\"text_label\"]\n",
    "            result_4 = train_data[f\"{id}_4\"][\"text_predict\"] if random.random() < q else train_data[f\"{id}_4\"][\"text_label\"]\n",
    "            result_5 = train_data[f\"{id}_5\"][\"text_predict\"] if random.random() < q else train_data[f\"{id}_5\"][\"text_label\"]\n",
    "            text_input = f\"Task 6, predict aspect term - opinion term - sentiment polarity - aspect category sets with results of task 3, 4, 5\\nInput: {text_sentence}\\nTask 3 results: {result_3}\\nTask 4 results: {result_4}\\nTask 5 results: {result_5}\"\n",
    "        \n",
    "        # Tokenize inputs and labels\n",
    "        text_inputs.append(text_input)\n",
    "        text_labels.append(text_label)\n",
    "    \n",
    "    # Tokenize the entire batch\n",
    "    tokenized_inputs = tokenizer(text_inputs, padding=True, return_tensors=\"pt\")\n",
    "    tokenized_labels = tokenizer(text_labels, padding=True, return_tensors=\"pt\")\n",
    "    tokenized_labels[\"input_ids\"][tokenized_labels[\"input_ids\"] == tokenizer.pad_token_id] = -100\n",
    "    # Return the batch as a dictionary\n",
    "    return {\n",
    "        \"batch_keys\": batch_keys,\n",
    "        \"input_ids\": tokenized_inputs[\"input_ids\"],\n",
    "        \"attention_mask\": tokenized_inputs[\"attention_mask\"],\n",
    "        \"labels\": tokenized_labels[\"input_ids\"],\n",
    "        # \"text_inputs\": text_inputs,\n",
    "        # \"text_labels\": text_labels,\n",
    "    }\n",
    "\n",
    "def build_dataloader(train_data, q, batch_size, tokenizer):\n",
    "    return DataLoader(\n",
    "        list(train_data.keys()),\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,  # Shuffle để tăng tính ngẫu nhiên\n",
    "        collate_fn=lambda batch_keys: collate_fn(batch_keys=batch_keys, train_data=train_data, q=q, tokenizer=tokenizer)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader = build_dataloader(train_data, 0.5, 1, T5Tokenizer.from_pretrained(\"t5-base\"))\n",
    "# max_len_input_ids = 0\n",
    "# max_len_labels = 0\n",
    "# for batch in dataloader:\n",
    "#     if max_len_input_ids < len(batch['input_ids'][0]):\n",
    "#         max_len_input_ids = len(batch['input_ids'][0])\n",
    "    \n",
    "#     if max_len_labels < len(batch['labels'][0]):\n",
    "#         max_len_labels = len(batch['labels'][0])\n",
    "# print(max_len_input_ids, max_len_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# xử lý tập validation và đánh giá mô hình"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === HÀM XỬ LÝ VALIDATION DATA ===\n",
    "def process_validation_data(validation_file):\n",
    "    # Đọc dữ liệu từ file\n",
    "    with open(validation_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        lines = f.readlines()\n",
    "    data = []\n",
    "    for line in lines:\n",
    "        text_sentence, aspect_category_sentiment_opinions_str = line.strip().split(\"####\")\n",
    "        data.append({\n",
    "            \"text_sentence\": text_sentence, \n",
    "            \"aspect_category_sentiment_opinions\": ast.literal_eval(aspect_category_sentiment_opinions_str)\n",
    "        })\n",
    "    return data\n",
    "\n",
    "# === HÀM ĐỂ CHẠY SUY LUẬN TRÊN BATCH ===\n",
    "def batch_predict(model, tokenizer, inputs, device):\n",
    "    encoded_inputs = tokenizer(inputs, return_tensors=\"pt\", padding=True).to(device)\n",
    "    outputs = model.generate(**encoded_inputs, max_length=124)\n",
    "    return tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "\n",
    "def evaluate_pipeline_batch(model, tokenizer, validation_data, device, batch_size):\n",
    "    # Initialize counters\n",
    "    count_true_positive = 0\n",
    "    count_false_positive = 0\n",
    "    count_false_negative = 0\n",
    "    \n",
    "    # Divide validation data into batches\n",
    "    for i in range(0, len(validation_data), batch_size):\n",
    "        batch = validation_data[i:i + batch_size]\n",
    "        text_sentences = [sample[\"text_sentence\"] for sample in batch]\n",
    "        text_labels = [sample[\"aspect_category_sentiment_opinions\"] for sample in batch]\n",
    "\n",
    "        # Step 1: Task 1 (I -> A)\n",
    "        task_1_inputs = [\n",
    "            f\"Task 1, predict aspect terms\\nInput: {text_sentence}\"\n",
    "            for text_sentence in text_sentences]\n",
    "        task_1_outputs = batch_predict(model, tokenizer, task_1_inputs, device)\n",
    "\n",
    "        # Step 2: Task 2 (I -> O)\n",
    "        task_2_inputs = [\n",
    "            f\"Task 2, predict opinion terms\\nInput: {text_sentence}\" \n",
    "            for text_sentence in text_sentences]\n",
    "        task_2_outputs = batch_predict(model, tokenizer, task_2_inputs, device)\n",
    "\n",
    "        # Step 3: Task 3 (I, A -> A-O)\n",
    "        task_3_inputs = [\n",
    "            f\"Task 3, predict aspect term - opinion term sets with these aspect terms\\nInput: {text_sentence}\\nAspect terms: {task_1_output}\"\n",
    "            for text_sentence, task_1_output in zip(text_sentences, task_1_outputs)\n",
    "        ]\n",
    "        task_3_outputs = batch_predict(model, tokenizer, task_3_inputs, device)\n",
    "\n",
    "        # Step 4: Task 4 (I, O -> A-O)\n",
    "        task_4_inputs = [\n",
    "            f\"Task 4, predict aspect term - opinion term sets with these opinion terms\\nInput: {text_sentence}\\nOpinion terms: {task_2_output}\"\n",
    "            for text_sentence, task_2_output in zip(text_sentences, task_2_outputs)\n",
    "        ]\n",
    "        task_4_outputs = batch_predict(model, tokenizer, task_4_inputs, device)\n",
    "\n",
    "        # Step 5: Task 5 (I, A, O -> A-O)\n",
    "        task_5_inputs = [\n",
    "            f\"Task 5, predict aspect term - opinion term sets with these aspect terms and opinion terms\\nInput: {text_sentence}\\nAspect terms: {task_1_output}\\nOpinion terms: {task_2_output}\"\n",
    "            for text_sentence, task_1_output, task_2_output in zip(text_sentences, task_1_outputs, task_2_outputs)\n",
    "        ]\n",
    "        task_5_outputs = batch_predict(model, tokenizer, task_5_inputs, device)\n",
    "\n",
    "        # Step 6: Task 6 (I, A-O -> A-O)\n",
    "        task_6_inputs = [\n",
    "            f\"Task 6, predict aspect term - opinion term - sentiment polarity - aspect category sets with results of task 3, 4, 5\\nInput: {text_sentence}\\nTask 3 results: {task_3_output}\\nTask 4 results: {task_4_output}\\nTask 5 results: {task_5_output}\"\n",
    "            for text_sentence, task_3_output, task_4_output, task_5_output in zip(text_sentences, task_3_outputs, task_4_outputs, task_5_outputs)\n",
    "        ]\n",
    "        task_6_outputs = batch_predict(model, tokenizer, task_6_inputs, device)\n",
    "        \n",
    "        # Evaluate predictions\n",
    "        for task_6_output, text_label in zip(task_6_outputs, text_labels):\n",
    "            predicted_set = set(task_6_output.split('; '))  # Split predictions into sets of tuples\n",
    "            true_set = set(f\"{aspect}, {opinion}, {sentiment}, {category}\" for aspect, category, sentiment, opinion in text_label) # Split ground truth into sets of tuples\n",
    "            # Calculate true positives, false positives, and false negatives\n",
    "            count_true_positive += len(predicted_set & true_set)\n",
    "            count_false_positive += len(predicted_set - true_set)\n",
    "            count_false_negative += len(true_set - predicted_set)\n",
    "    \n",
    "    # Compute Precision, Recall, and F1-score\n",
    "    precision = count_true_positive / (count_true_positive + count_false_positive) if count_true_positive + count_false_positive > 0 else 0\n",
    "    recall = count_true_positive / (count_true_positive + count_false_negative) if count_true_positive + count_false_negative > 0 else 0\n",
    "    f1 = (2 * precision * recall) / (precision + recall) if precision + recall > 0 else 0\n",
    "    \n",
    "    return precision, recall, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Đánh giá trên tập test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1577178/2786177602.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"/chain-of-thought-ABSA/results/experiment_5/15.pt\"))\n",
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4256816182937555, 0.4186851211072664, 0.4221543829044919)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_data = process_validation_data(\"/chain-of-thought-ABSA/data/acos/laptop16/test.txt\")\n",
    "\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"t5-base\")\n",
    "model.load_state_dict(torch.load(\"/chain-of-thought-ABSA/results/experiment_5/15.pt\"))\n",
    "model.eval()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "evaluate_pipeline_batch(\n",
    "    model=model, \n",
    "    tokenizer = T5Tokenizer.from_pretrained(\"t5-base\"), \n",
    "    validation_data = validation_data, \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"), \n",
    "    batch_size = 16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Huấn luyện"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_after_eos(output_ids):\n",
    "    cleaned_output = []\n",
    "    for sequence in output_ids:\n",
    "        eos_position = (sequence == 1).nonzero(as_tuple=True)[0]\n",
    "        if len(eos_position) > 0:  # Nếu tìm thấy <EOS>\n",
    "            cleaned_output.append(sequence[: eos_position[0]])  # Giữ lại từ đầu đến trước <EOS>\n",
    "        else:\n",
    "            cleaned_output.append(sequence)  # Không có <EOS>, giữ nguyên\n",
    "    return cleaned_output\n",
    "\n",
    "# Hàm huấn luyện\n",
    "def train_model(model, tokenizer, train_data, validation_data, num_epochs, batch_size, lr, q_step):\n",
    "    # no_improve_epochs = 0\n",
    "    q = 0\n",
    "    best_f1 = 0\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    dataloader = build_dataloader(train_data=train_data, q = q, batch_size=batch_size, tokenizer=tokenizer)\n",
    "    optimizer = AdamW(model.parameters(), lr=lr)\n",
    "    for epoch in range(num_epochs):\n",
    "        torch.cuda.empty_cache()\n",
    "        # Huấn luyện #########################################################################################################################################\n",
    "        print(f\"Training epoch {epoch + 1}\")\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for batch in dataloader:\n",
    "            outputs = model(\n",
    "                input_ids=batch[\"input_ids\"].to(device), \n",
    "                attention_mask=batch[\"attention_mask\"].to(device), \n",
    "                labels=batch[\"labels\"].to(device))\n",
    "            loss = outputs.loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            total_loss += loss.item()\n",
    "            # Lưu dự đoán vào train_data\n",
    "            if random.random() < q:\n",
    "                for key, sequence in zip(batch[\"batch_keys\"], torch.argmax(outputs.logits, dim=-1)):\n",
    "                    eos_position = (sequence == 1).nonzero(as_tuple=True)[0]\n",
    "                    if len(eos_position) > 0:  # Nếu tìm thấy <EOS>\n",
    "                        train_data[key][\"text_predict\"] = tokenizer.decode(sequence[: eos_position[0]], skip_special_tokens=True)\n",
    "                    else:\n",
    "                        train_data[key][\"text_predict\"] = tokenizer.decode(sequence, skip_special_tokens=True) # Không có <EOS>, giữ nguyên\n",
    "                    \n",
    "        print(f\"Epoch {epoch + 1} finished with loss: {total_loss / len(dataloader):.4f}\")\n",
    "        # Đánh giá #########################################################################################################################################\n",
    "        print(\"Evaluating\")\n",
    "        model.eval()\n",
    "        precision, recall, f1 = evaluate_pipeline_batch(model, tokenizer, validation_data, device, batch_size)\n",
    "        print(\"precision =\", precision,\"recall =\", recall,\"f1 =\", f1)\n",
    "        if(f1 > best_f1):\n",
    "            # no_improve_epochs = 0\n",
    "            best_f1 = f1\n",
    "            # Lưu model\n",
    "            torch.save(model.state_dict(), f\"/chain-of-thought-ABSA/results/experiment_4/{epoch + 1}.pt\")\n",
    "            print(\"New best_f1 =\", best_f1)\n",
    "        else:\n",
    "            if (q >= 1):\n",
    "                print(\"Huấn huyện xong\")\n",
    "                break\n",
    "            q = q + q_step\n",
    "            print(\"q =\", q)\n",
    "            dataloader = build_dataloader(train_data=train_data, q = q, batch_size=batch_size, tokenizer=tokenizer)\n",
    "            # no_improve_epochs = no_improve_epochs + 1\n",
    "            # if no_improve_epochs == 5:\n",
    "            #     print(\"Huấn huyện xong\")\n",
    "            #     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data = process_train_data(\"/chain-of-thought-ABSA/data/acos/laptop16/train.txt\")\n",
    "\n",
    "# train_model(\n",
    "#     model = T5ForConditionalGeneration.from_pretrained(\"t5-base\"), \n",
    "#     tokenizer = T5Tokenizer.from_pretrained(\"t5-base\"), \n",
    "#     train_data = train_data,\n",
    "#     validation_data = process_validation_data(\"/chain-of-thought-ABSA/data/acos/laptop16/dev.txt\"),\n",
    "#     num_epochs = 1000,\n",
    "#     batch_size = 8, \n",
    "#     lr = 3e-5,\n",
    "#     q_step=0.05,\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
